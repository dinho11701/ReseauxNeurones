import streamlit as st
import numpy as np
from PIL import Image
from scipy.spatial import distance
import matplotlib.pyplot as plt
import glob
from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3
from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg
from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet
from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_inception
from tensorflow.keras.preprocessing.image import img_to_array

# --- Interface utilisateur ---
st.title("üîç Recherche d'images similaires")

uploaded_file = st.file_uploader("üì§ T√©l√©versez une image requ√™te", type=["jpg", "jpeg", "png"])

model_name = st.selectbox("üß† Choisissez un descripteur :", ["VGG16", "ResNet50", "InceptionV3"])
metric = st.selectbox("üìè Choisissez une m√©trique :", ["Euclidienne", "Manhattan", "Chebyshev", "Canberra"])

if uploaded_file is not None:
    query_img = Image.open(uploaded_file).convert("RGB")
    st.image(query_img, caption="Image requ√™te", use_column_width=True)

    if st.button("üîé Lancer la recherche"):
        # Chargement des fichiers correspondant au mod√®le choisi
        vec_path = f"data/{model_name}_vectors.npy"
        label_path = f"data/{model_name}_labels.npy"
        img_path = f"data/{model_name}_paths.npy"

        DB_VECTORS = np.load(vec_path)
        DB_LABELS = np.load(label_path)
        IMAGE_PATHS = np.load(img_path, allow_pickle=True)

        # Chargement du mod√®le et du pr√©traitement
        if model_name == "VGG16":
            model = VGG16(weights="imagenet", include_top=False, pooling="avg")
            size = (224, 224)
            preprocess = preprocess_vgg
        elif model_name == "ResNet50":
            model = ResNet50(weights="imagenet", include_top=False, pooling="avg")
            size = (224, 224)
            preprocess = preprocess_resnet
        elif model_name == "InceptionV3":
            model = InceptionV3(weights="imagenet", include_top=False, pooling="avg")
            size = (299, 299)
            preprocess = preprocess_inception

        # Pr√©traitement et extraction du vecteur requ√™te
        img = query_img.resize(size)
        arr = img_to_array(img)
        arr = np.expand_dims(arr, axis=0)
        arr = preprocess(arr)
        query_vec = model.predict(arr).flatten()

        # Calcul des distances
        def compute_distance(vec1, vec2, metric):
            if metric == "Euclidienne":
                return distance.euclidean(vec1, vec2)
            elif metric == "Manhattan":
                return distance.cityblock(vec1, vec2)
            elif metric == "Chebyshev":
                return distance.chebyshev(vec1, vec2)
            elif metric == "Canberra":
                return distance.canberra(vec1, vec2)
            else:
                raise ValueError("M√©trique non support√©e.")

        distances = [compute_distance(query_vec, vec, metric) for vec in DB_VECTORS]
        top_indices = np.argsort(distances)[:5]

        # Affichage des r√©sultats
        st.subheader("üñºÔ∏è Images les plus proches :")
        for i in top_indices:
            st.image(IMAGE_PATHS[i], caption=f"Label : {DB_LABELS[i]} ‚Äî Distance : {distances[i]:.2f}", width=150)

        st.subheader("üìä Analyse des labels :")
        top_labels = [DB_LABELS[i] for i in top_indices]
        unique, counts = np.unique(top_labels, return_counts=True)

        fig, ax = plt.subplots()
        ax.bar(unique, counts)
        ax.set_xlabel("Label")
        ax.set_ylabel("Fr√©quence")
        ax.set_title("R√©partition des labels parmi les plus proches")
        st.pyplot(fig)

        st.success("‚úÖ Analyse termin√©e")

